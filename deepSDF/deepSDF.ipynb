{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "if os.getcwd().split(\"\\\\\")[-1] != \"toytorch\":\n",
    "    os.chdir(os.path.join(os.getcwd(), \"../\"))\n",
    "\n",
    "from deepSDF.config import Configuration\n",
    "from deepSDF.synthesize import Synthesizer\n",
    "from deepSDF.model import SDFdataset, SDFdecoder, SDFdecoderTrainer\n",
    "from deepSDF.data.data_creator import DataCreator, DataCreatorHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing raw skyscrapers\n",
    "\n",
    "path = Configuration.RAW_DATA_PATH\n",
    "meshes = trimesh.Trimesh(vertices=[], faces=[])\n",
    "\n",
    "for i, file in enumerate(os.listdir(path)):\n",
    "    if file.endswith(\".obj\"):\n",
    "        mesh = trimesh.load(os.path.join(path, file))\n",
    "\n",
    "        if isinstance(mesh, trimesh.Scene):\n",
    "            geo_list = []\n",
    "            for g in mesh.geometry.values():\n",
    "                geo_list.append(g)\n",
    "            mesh = trimesh.util.concatenate(geo_list)\n",
    "\n",
    "        mesh.fix_normals(multibody=True)\n",
    "        \n",
    "        meshes += mesh\n",
    "        \n",
    "# If you want to see the raw data, uncomment the following lines.\n",
    "\n",
    "# scene = trimesh.Scene(meshes)\n",
    "# scene.set_camera(angles=[90, 90, 90])\n",
    "# scene.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-31 13:10:21,929\tINFO worker.py:1724 -- Started a local Ray instance.\n",
      "Preprocessing:   0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh_vertices_count: 402002 n_total_sampling: 262144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing:   7%|▋         | 1/15 [00:04<01:09,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh_vertices_count: 252401 n_total_sampling: 262144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing:  13%|█▎        | 2/15 [00:08<00:56,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh_vertices_count: 376270 n_total_sampling: 262144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing:  20%|██        | 3/15 [00:13<00:55,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh_vertices_count: 361366 n_total_sampling: 262144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing:  27%|██▋       | 4/15 [00:19<00:57,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh_vertices_count: 313170 n_total_sampling: 262144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing:  33%|███▎      | 5/15 [00:24<00:48,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh_vertices_count: 194112 n_total_sampling: 262144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing:  40%|████      | 6/15 [00:27<00:37,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh_vertices_count: 448575 n_total_sampling: 262144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing:  47%|████▋     | 7/15 [00:33<00:39,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh_vertices_count: 716551 n_total_sampling: 262144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing:  53%|█████▎    | 8/15 [00:46<00:51,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh_vertices_count: 400686 n_total_sampling: 262144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing:  60%|██████    | 9/15 [00:50<00:39,  6.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh_vertices_count: 282146 n_total_sampling: 262144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing:  67%|██████▋   | 10/15 [00:56<00:31,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh_vertices_count: 376330 n_total_sampling: 262144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing:  73%|███████▎  | 11/15 [01:03<00:25,  6.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh_vertices_count: 490262 n_total_sampling: 262144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing:  80%|████████  | 12/15 [01:09<00:18,  6.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh_vertices_count: 346453 n_total_sampling: 262144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing:  87%|████████▋ | 13/15 [01:17<00:13,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh_vertices_count: 655553 n_total_sampling: 262144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing:  93%|█████████▎| 14/15 [01:26<00:07,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mesh_vertices_count: 520294 n_total_sampling: 262144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|██████████| 15/15 [01:32<00:00,  6.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The function create took 208.49423742294312 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing data\n",
    "\n",
    "data_creator = DataCreator(\n",
    "    n_surface_sampling=Configuration.N_SURFACE_SAMPLING,\n",
    "    n_bbox_sampling=Configuration.N_BBOX_SAMPLING,\n",
    "    n_volume_sampling=Configuration.N_VOLUME_SAMPLING,\n",
    "    raw_data_path=Configuration.RAW_DATA_PATH,\n",
    "    save_path=Configuration.SAVE_DATA_PATH,\n",
    "    translate_mode=DataCreatorHelper.CENTER_WITHOUT_Z,\n",
    "    dynamic_sampling=False,\n",
    "    is_debug_mode=False,\n",
    ")\n",
    "\n",
    "data_creator.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA status\n",
      "  torch.cuda.is_available(): True\n",
      "  DEVICE: cuda \n",
      "\n",
      "Seeds status:\n",
      "  Seeds set for torch        : 77777\n",
      "  Seeds set for torch on GPU : 77777\n",
      "  Seeds set for numpy        : 77777\n",
      "  Seeds set for random       : 77777 \n",
      "\n",
      "Set all pre-trained states from deepSDF\\runs\\2024-03-24_12-40-26\\states\\all_states.pth \n",
      "\n",
      "Set all dataloaders\n",
      "  TRAIN_DATASET_RATIO: 0.8\n",
      "  VAL_DATASET_RATIO: 0.2 \n",
      "\n",
      "Set all pre-trained optimizers \n",
      "\n",
      "Set all pre-trained weights \n",
      "\n",
      "best_loss: 0.13492946143469453 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\park1\\anaconda3\\envs\\pytorch-exercise\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 141th epoch took 1019.885041475296 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 142th Train Loss: 0.13484037555925474, Val Loss: 0.13492944790535452\n",
      "Epoch: 142th epoch took 997.0486843585968 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143th epoch took 1022.3658022880554 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 144th Train Loss: 0.13484036150005826, Val Loss: 0.13492942921220674\n",
      "Epoch: 144th epoch took 1010.7984998226166 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 145th Train Loss: 0.13484035356661175, Val Loss: 0.13492942143420805\n",
      "Epoch: 145th epoch took 1031.6639952659607 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 146th epoch took 1048.487384557724 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 147th Train Loss: 0.13484034106265122, Val Loss: 0.1349294140651788\n",
      "Epoch: 147th epoch took 1021.6076176166534 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 148th epoch took 1012.7693212032318 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 149th epoch took 999.1915583610535 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 150th Train Loss: 0.13484031601835036, Val Loss: 0.1349294129622649\n",
      "Epoch: 150th epoch took 1017.3521234989166 seconds\n"
     ]
    }
   ],
   "source": [
    "# Training model\n",
    "\n",
    "sdf_dataset = SDFdataset()\n",
    "sdf_decoder = SDFdecoder(cls_nums=sdf_dataset.cls_nums)\n",
    "sdf_trainer = SDFdecoderTrainer(\n",
    "    sdf_dataset=sdf_dataset,\n",
    "    sdf_decoder=sdf_decoder,\n",
    "    is_debug_mode=False,\n",
    "    seed=77777,\n",
    "    pre_trained_path=r\"deepSDF\\runs\\2024-03-24_12-40-26\",\n",
    ")\n",
    "\n",
    "sdf_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA status\n",
      "  torch.cuda.is_available(): True\n",
      "  DEVICE: cuda \n",
      "\n",
      "Seeds status:\n",
      "  Seeds set for torch        : 77777\n",
      "  Seeds set for torch on GPU : 77777\n",
      "  Seeds set for numpy        : 77777\n",
      "  Seeds set for random       : 77777 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualizing reconstructed skyscrapers from the trained latent codes\n",
    "\n",
    "\"\"\"\n",
    "    cls_dict = {\n",
    "        0: 'bank_of_china',\n",
    "        1: 'burj_al_arab',\n",
    "        2: 'cctv_headquarter',\n",
    "        3: 'china_zun',\n",
    "        4: 'empire_state_building',\n",
    "        5: 'hearst_tower',\n",
    "        6: 'kingdom_centre',\n",
    "        7: 'lotte_tower',\n",
    "        8: 'mahanakhon',\n",
    "        9: 'one_world_trade_center',\n",
    "        10: 'shanghai_world_financial_center',\n",
    "        11: 'taipei_101',\n",
    "        12: 'the_gherkin',\n",
    "        13: 'the_shard',\n",
    "        14: 'transamerica_pyramid'\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "all_states = torch.load(r\"deepSDF\\runs\\2024-03-24_12-40-26\\states\\all_states.pth\")\n",
    "cls_dict = all_states[\"cls_dict\"]\n",
    "\n",
    "sdf_decoder = SDFdecoder(cls_nums=max(cls_dict.keys()) + 1)\n",
    "sdf_decoder.load_state_dict(all_states[\"model_d\"])\n",
    "sdf_decoder.latent_codes = nn.Parameter(all_states[\"latent_codes\"])\n",
    "\n",
    "sdf_trainer = SDFdecoderTrainer(\n",
    "    sdf_dataset=None,\n",
    "    sdf_decoder=sdf_decoder,\n",
    "    seed=77777,\n",
    "    is_reconstruct_mode=True,\n",
    ")\n",
    "\n",
    "os.makedirs(r\"deepSDF\\runs\\2024-03-24_12-40-26\\reconstructed_after_training\", exist_ok=True)\n",
    "\n",
    "mesh_interval = 1\n",
    "meshes = trimesh.Trimesh(vertices=[], faces=[])\n",
    "for cls_num in cls_dict.keys():\n",
    "    \n",
    "    obj_path = f\"deepSDF\\\\runs\\\\2024-03-24_12-40-26\\\\reconstructed_after_training\\\\{cls_num}.obj\"\n",
    "    \n",
    "    if os.path.exists(obj_path.replace(\".obj\", f\"_{None}_{cls_dict[cls_num]}.obj\")):\n",
    "        continue\n",
    "\n",
    "    sdf_trainer.reconstruct(\n",
    "        sdf_decoder=sdf_decoder,\n",
    "        cls_dict=cls_dict,\n",
    "        obj_path=obj_path,\n",
    "        epoch=None,\n",
    "        cls_num=cls_num,\n",
    "        map_z_to_y=True,\n",
    "    )\n",
    "    \n",
    "    mesh = trimesh.load(obj_path.replace(\".obj\", f\"_{None}_{cls_dict[cls_num]}.obj\"))\n",
    "\n",
    "    if isinstance(mesh, trimesh.Scene):\n",
    "        geo_list = []\n",
    "        for g in mesh.geometry.values():\n",
    "            geo_list.append(g)\n",
    "        mesh = trimesh.util.concatenate(geo_list)\n",
    "\n",
    "    mesh.fix_normals(multibody=True)\n",
    "    \n",
    "    mesh.vertices += np.array([mesh_interval * cls_num, 0, 0])\n",
    "    \n",
    "    meshes += mesh\n",
    "    \n",
    "# If you want to see the skyscrapers generated by model, uncomment the following lines.\n",
    "\n",
    "# scene = trimesh.Scene(meshes)\n",
    "# scene.set_camera(angles=[90, 90, 90])\n",
    "# scene.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthesizing trained data\n",
    "\n",
    "import os\n",
    "\n",
    "if os.getcwd().split(\"\\\\\")[-1] != \"toytorch\":\n",
    "    os.chdir(os.path.join(os.getcwd(), \"../\"))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import gc\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "from deepSDF.model import SDFdecoder\n",
    "from deepSDF.synthesize import Synthesizer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    cls_dict = {\n",
    "        0: 'bank_of_china',\n",
    "        1: 'burj_al_arab',\n",
    "        2: 'cctv_headquarter',\n",
    "        3: 'china_zun',\n",
    "        4: 'empire_state_building',\n",
    "        5: 'hearst_tower',\n",
    "        6: 'kingdom_centre',\n",
    "        7: 'lotte_tower',\n",
    "        8: 'mahanakhon',\n",
    "        9: 'one_world_trade_center',\n",
    "        10: 'shanghai_world_financial_center',\n",
    "        11: 'taipei_101',\n",
    "        12: 'the_gherkin',\n",
    "        13: 'the_shard',\n",
    "        14: 'transamerica_pyramid'\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "all_states = torch.load(r\"deepSDF\\runs\\2024-03-24_12-40-26\\states\\all_states.pth\")\n",
    "cls_dict = all_states[\"cls_dict\"]\n",
    "cls_nums = max(cls_dict.keys()) + 1\n",
    "\n",
    "sdf_decoder = SDFdecoder(cls_nums=cls_nums)\n",
    "sdf_decoder.load_state_dict(all_states[\"model_d\"])\n",
    "sdf_decoder.latent_codes = nn.Parameter(all_states[\"latent_codes\"])\n",
    "\n",
    "synthesizer = Synthesizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthesizing trained data by interpolating two latent codes\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "\n",
    "synthesized_dir = r\"deepSDF\\runs\\2024-03-24_12-40-26\\synthesized\"\n",
    "synthesized_latent_codes_npz = \"synthesized_latent_codes.npz\"\n",
    "synthesized_latent_codes_path = os.path.join(synthesized_dir, synthesized_latent_codes_npz)\n",
    "\n",
    "os.makedirs(synthesized_dir, exist_ok=True)\n",
    "\n",
    "synthesized_latent_codes = {\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"name\": i,\n",
    "            \"index\": i,\n",
    "            \"interpolation_factor\": None,\n",
    "            \"latent_code\": list(latent_code.detach().cpu().numpy()),\n",
    "        } for i, latent_code in enumerate(sdf_decoder.latent_codes)\n",
    "    ] \n",
    "}\n",
    "\n",
    "if os.path.exists(synthesized_latent_codes_path):\n",
    "    synthesized_latent_codes = {\n",
    "        \"data\": list(np.load(synthesized_latent_codes_path, allow_pickle=True)[\"synthesized_data\"])\n",
    "    }\n",
    "        \n",
    "while len([f for f in os.listdir(synthesized_dir) if f.endswith(\".obj\")]) < 135:\n",
    "    \n",
    "    print(\n",
    "        f\"len([f for f in os.listdir(synthesized_dir) if f.endswith('.obj')]): \\\n",
    "        {len([f for f in os.listdir(synthesized_dir) if f.endswith('.obj')])}\"\n",
    "    )\n",
    "    \n",
    "    data_to_sample = synthesized_latent_codes[\"data\"]\n",
    "    \n",
    "    if random.Random(time.time()).random() < 0.5:\n",
    "        data_to_sample = data_to_sample[:len(sdf_decoder.latent_codes)]\n",
    "    \n",
    "    data_1, data_2 = random.Random(time.time()).sample(data_to_sample, 2)\n",
    "    \n",
    "    latent_code_1 = data_1[\"latent_code\"]\n",
    "    latent_code_1 = torch.tensor(latent_code_1).to(sdf_decoder.latent_codes.device)\n",
    "    latent_code_1_index = data_1[\"index\"]\n",
    "    \n",
    "    latent_code_2 = data_2[\"latent_code\"]\n",
    "    latent_code_2 = torch.tensor(latent_code_2).to(sdf_decoder.latent_codes.device)\n",
    "    latent_code_2_index = data_2[\"index\"]\n",
    "    \n",
    "    random_interpolation_factor = round(0.25 + (0.75 - 0.25) * random.Random(time.time()).random(), 3)\n",
    "    \n",
    "    synthesized_latent_code = synthesizer.interpolate(\n",
    "        latent_codes=[latent_code_1, latent_code_2],\n",
    "        factors=[random_interpolation_factor]\n",
    "    )\n",
    "    \n",
    "    name = f\"{latent_code_1_index}__{latent_code_2_index}__{str(random_interpolation_factor).replace('.', '-')}.obj\"\n",
    "    save_name = os.path.join(synthesized_dir, name)\n",
    "    \n",
    "    if os.path.exists(save_name):\n",
    "        continue\n",
    "    \n",
    "    synthesized_mesh = synthesizer.synthesize(\n",
    "        sdf_decoder=sdf_decoder,\n",
    "        latent_code=synthesized_latent_code,\n",
    "        resolution=384,\n",
    "        save_name=save_name,\n",
    "        map_z_to_y=True,\n",
    "        check_watertight=True,\n",
    "    )\n",
    "\n",
    "    synthesized_data = {\n",
    "        \"name\": name,\n",
    "        \"index\": len(synthesized_latent_codes[\"data\"]),\n",
    "        \"interpolation_factor\": random_interpolation_factor,\n",
    "        \"latent_code\": list(synthesized_latent_code.detach().cpu().numpy()),\n",
    "    }\n",
    "    \n",
    "    synthesized_latent_codes[\"data\"].append(synthesized_data)\n",
    "    \n",
    "    np.savez(\n",
    "        synthesized_latent_codes_path,\n",
    "        synthesized_data=np.array(synthesized_latent_codes[\"data\"]),\n",
    "    )\n",
    "    \n",
    "    clear_output(wait=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthesizing trained data by adding and subtracting three latent codes\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "\n",
    "synthesized_dir = r\"deepSDF\\runs\\2024-03-24_12-40-26\\synthesized\"\n",
    "synthesized_latent_codes_npz = \"synthesized_latent_codes_2.npz\"\n",
    "synthesized_latent_codes_path = os.path.join(synthesized_dir, synthesized_latent_codes_npz)\n",
    "\n",
    "os.makedirs(synthesized_dir, exist_ok=True)\n",
    "\n",
    "synthesized_latent_codes = {\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"name\": i,\n",
    "            \"index\": i,\n",
    "            \"latent_code\": list(latent_code.detach().cpu().numpy()),\n",
    "        } for i, latent_code in enumerate(sdf_decoder.latent_codes)\n",
    "    ] \n",
    "}\n",
    "\n",
    "if os.path.exists(synthesized_latent_codes_path):\n",
    "    synthesized_latent_codes = {\n",
    "        \"data\": list(np.load(synthesized_latent_codes_path, allow_pickle=True)[\"synthesized_data\"])\n",
    "    }\n",
    "    \n",
    "        \n",
    "while len([f for f in os.listdir(synthesized_dir) if f.endswith(\".obj\")]) < 300 - 15:\n",
    "    \n",
    "    print(\n",
    "        f\"len([f for f in os.listdir(synthesized_dir) if f.endswith('.obj')]): \\\n",
    "        {len([f for f in os.listdir(synthesized_dir) if f.endswith('.obj')])}\"\n",
    "    )\n",
    "    \n",
    "    data_to_sample = synthesized_latent_codes[\"data\"]\n",
    "    \n",
    "    if random.Random(time.time()).random() < 0.5:\n",
    "        data_to_sample = data_to_sample[:len(sdf_decoder.latent_codes)]\n",
    "    \n",
    "    random_data = random.Random(time.time()).sample(data_to_sample, 3)\n",
    "    \n",
    "    selected_indices = str(random_data[0][\"index\"])\n",
    "    synthesized_latent_code = torch.tensor(random_data[0][\"latent_code\"]).to(sdf_decoder.latent_codes.device)\n",
    "    for rdi, rd in enumerate(random_data[1:]):\n",
    "        if rdi != len(random_data[1:]) - 1:\n",
    "            synthesized_latent_code += torch.tensor(rd[\"latent_code\"]).to(sdf_decoder.latent_codes.device)\n",
    "        else:\n",
    "            synthesized_latent_code -= torch.tensor(rd[\"latent_code\"]).to(sdf_decoder.latent_codes.device)\n",
    "            \n",
    "        selected_indices += \"__\" + str(rd[\"index\"])\n",
    "    \n",
    "    name = f\"{selected_indices}.obj\"\n",
    "    save_name = os.path.join(synthesized_dir, name)\n",
    "    \n",
    "    print(save_name)\n",
    "    \n",
    "    if os.path.exists(save_name):\n",
    "        continue\n",
    "    \n",
    "    synthesized_mesh = synthesizer.synthesize(\n",
    "        sdf_decoder=sdf_decoder,\n",
    "        latent_code=synthesized_latent_code,\n",
    "        resolution=384,\n",
    "        save_name=save_name,\n",
    "        map_z_to_y=True,\n",
    "        check_watertight=True,\n",
    "    )\n",
    "\n",
    "    synthesized_data = {\n",
    "        \"name\": name,\n",
    "        \"index\": len(synthesized_latent_codes[\"data\"]),\n",
    "        \"latent_code\": list(synthesized_latent_code.detach().cpu().numpy()),\n",
    "    }\n",
    "    \n",
    "    synthesized_latent_codes[\"data\"].append(synthesized_data)\n",
    "    \n",
    "    np.savez(\n",
    "        synthesized_latent_codes_path,\n",
    "        synthesized_data=np.array(synthesized_latent_codes[\"data\"]),\n",
    "    )\n",
    "    \n",
    "    clear_output(wait=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-exercise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
